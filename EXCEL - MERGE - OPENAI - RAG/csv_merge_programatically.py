# -*- coding: utf-8 -*-
"""CSV-MERGE-PROGRAMATICALLY.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pDl1uOp4GaXD5GcBsiZOJ-3huimG3He3
"""

# pip -q install langchain langchain-community langchain-openai openai langchain_experimental langchain-groq gradio

import pandas as pd
import glob
import os
import ast
import openai
from openai import OpenAI
from langchain_core.prompts import PromptTemplate
import json
from io import StringIO
from langchain_groq import ChatGroq
from langchain_experimental.agents.agent_toolkits import create_csv_agent
from google.colab import files
import numpy as np

folder_path='/content/data-csv'
file_paths = glob.glob(os.path.join(folder_path, '*.csv'))
file_paths

def load_csv_content(file_path):
    """
    Load a CSV file and return its content as a string.

    :param file_path: Path to the CSV file.
    :return: CSV content as a string.
    """
    df = pd.read_csv(file_path)
    return df.to_csv(index=False)

def prepare_files_for_prompt(file_paths):
    """
    Prepare a list of files in a format suitable for passing to the OpenAI API.

    :param file_paths: List of file paths.
    :return: List of dictionaries, each containing the filename and content.
    """
    files = []
    for path in file_paths:
        content = load_csv_content(path)
        files.append({"filename": path.split("/")[-1], "content": content})
    return files

file_contents = prepare_files_for_prompt(file_paths)

file_contents

from google.colab import userdata
os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI')
openai.api_key = os.environ['OPENAI_API_KEY']
client = OpenAI()

groq_api = 'YOUR GROQ API'
llm = ChatGroq(temperature=0, model="llama3-70b-8192", api_key=groq_api)

from pydantic import BaseModel
class Response(BaseModel):
  mapping:dict

def generate_mapping_response(files):
    response = client.chat.completions.create(
        model="gpt-4o-2024-08-06",
        messages=[
            {
                "role": "system",
                "content": "You are an expert in data processing and merging financial and accounts data from CSV files. Your task is to analyze the columns and generate a precise mapping."
            },
            {
                "role": "user",
                "content": """You are given several CSV files containing financial and accounts data. Your task is to:

                1. **Identify Similar Columns:** Analyze the columns in each CSV file by comparing both column names and data content. Ensure that columns with different names but similar data are mapped together.

                2. **Generate Column Mapping:** Create a mapping of similar columns across all CSV files. For columns that do not match, keep them separate in the final mapping with their original names.

                3. **Output:** Provide a object containing the mapping for each file. The format should be:
                   - { 'File-1': {'OriginalColumnName1': 'MappedColumnName', 'OriginalColumnName2': 'MappedColumnName'}, 'File-2': {'OriginalColumnName3': 'MappedColumnName', ...}, ... }

                ### Additional Instructions:
                - Ensure that similar columns are mapped accurately, even if their names differ.
                - Focus on correctly identifying and mapping financial and accounts-related columns.
                - No need to merge the files, just provide the mapping."""
            },
            {
                "role":"user",
                "content":"Give only the mapping as response,nothing else,response should an Dictionary with single quotes around it"
            },
            {
                "role":"user",
                "content":"Map every file to last file column names, and keep last file column names mapped to itself"
            },
            {
                "role": "user",
                "content": f"Here are the contents of the CSV files: {files}"
            }
        ],
        temperature=0
    )

    return response.choices[0].message.content

dict_str=generate_mapping_response(file_contents)

mapping = ast.literal_eval(dict_str)

mapping,file_paths

def rename_and_merge_csv_files(mapping,file_paths):
  renamed_dfs=[]

  all_columns =[]
  for file in file_paths:
    file_name=file[file.rindex('/')+1:]
    for column in mapping[file_name].values():
      if column not in all_columns:
        all_columns.append(column)

  for file in file_paths:
    file_name=file[file.rindex('/')+1:]
    df=pd.read_csv(file)
    df=df.rename(columns=mapping[file_name])
    for column in all_columns:
      if column not in df.columns:
        df[column] = np.nan
    renamed_dfs.append(df)

  return pd.concat(renamed_dfs, axis=0, ignore_index=True)



merged_df=rename_and_merge_csv_files(mapping,file_paths)

merged_df

def mkdir(merged_df):
  folder_path = '/content/normalized_data_folder'
  file_name = 'normalized_data.csv'
  file_path = os.path.join(folder_path, file_name)

  # Create the directory if it does not exist
  os.makedirs(folder_path, exist_ok=True)
  merged_df.to_csv(file_path, index=False)
  return file_path
file_path=mkdir(merged_df)

agent = create_csv_agent(llm,file_path, verbose=True, allow_dangerous_code=True)

def query_data(query):
    response = agent.invoke(query)
    return response

query = "total income and specifically mention which manager brought how much income"
response = query_data(query)
print(response['output'])

import gradio as gr


def processing(query):
        response = query_data(query)
        return response['output']

demo = gr.Interface(
    fn=processing,
    inputs=["text"],
    outputs=["text"],
)

demo.launch(debug=True)


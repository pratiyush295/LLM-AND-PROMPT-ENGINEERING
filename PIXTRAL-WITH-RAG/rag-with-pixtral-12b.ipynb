{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from vllm import LLM\n",
    "from vllm.sampling_params import SamplingParams\n",
    "from qdrant_client.models import Distance, VectorParams\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from qdrant_client.models import PointStruct\n",
    "from groq import Groq\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=os.getenv(\"HUGGING_FACE_TOKE\"))\n",
    "groq_api = Groq(api_key = os.getenv(\"GROQ_API\"))\n",
    "                \n",
    "model_name= \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model_kwargs = {\"device\": \"cpu\"}\n",
    "\n",
    "embeddings = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=LLM(\n",
    "    model=\"mistral-community/pixtral-12b-240910\",\n",
    "    tokenizer_mode=\"mistral\",\n",
    "    max_model_len=5000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_client = QdrantClient(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(image_url, prompt = \"Extract the information from the image\"):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    outputs = llm.chat(\n",
    "        messages,\n",
    "        sampling_params=SamplingParams(max_tokens=8192)\n",
    "    )\n",
    "\n",
    "    return outputs[0].outputs[0].text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(data_text):\n",
    "  return embeddings.encode(data_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_qdrant(length: int):\n",
    "    vector_size = length\n",
    "    # Define the vectors configuration\n",
    "    vector_params = VectorParams(\n",
    "        size=vector_size,                # Size of the vectors\n",
    "        distance=Distance.COSINE         # Choose distance metric (COSINE, EUCLID, or IP)\n",
    "    )\n",
    "    \n",
    "    # Create the collection with the specified configuration\n",
    "    qdrant_client.create_collection(\n",
    "        collection_name=\"CHATBOT\",\n",
    "        vectors_config=vector_params  # Specify vector configuration\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def prepare_embeddings(data, batch_size = 1):\n",
    "     data = data.split('\\n')\n",
    "     \n",
    "     for it in range(len(data)):\n",
    "         data[it] = [data[it]]\n",
    "        \n",
    "         \n",
    "     total_items = len(data)\n",
    "     batched_data = []\n",
    " \n",
    "     for start in range(0, total_items, batch_size):\n",
    "         end = min(start + batch_size, total_items)\n",
    "         batch = [item for item in data[start:end]]  # Extract contexts for this batch\n",
    "         vectors = generate_embeddings(batch)  # Generate embeddings for the batch\n",
    "\n",
    "         for i, vector in enumerate(vectors):\n",
    "             data[start + i].append(vector)  # Append vector to the corresponding item\n",
    "     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qdrant_entry(final_data):\n",
    "    points=[PointStruct( id=i,  vector=final_data[i][2],payload={'raw_context':final_data[i][0] }) for i in range(len(final_data))]\n",
    "    qdrant_client.upsert(collection_name=\"CHATBOT\", points=points)\n",
    "    print(qdrant_client.get_collections())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def query_qdrant(query, collection_name='CHATBOT', limit=4):\n",
    "    query_vector=generate_embeddings(query)\n",
    "    result = qdrant_client.search(\n",
    "        collection_name=\"CHATBOT\",\n",
    "        query_vector=query_vector,\n",
    "        limit=limit,\n",
    "        with_vectors=False\n",
    "    )\n",
    "    search_result=[]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def respond(question):\n",
    "    chat_completion = groq_api.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"This is the question asked by user {question} and the context given is {'-----'.join(query_qdrant(question))} answer this question based on the context provided\",\n",
    "            }\n",
    "                ],\n",
    "                model=\"llama-3.1-70b-versatile\",\n",
    "            )\n",
    "\n",
    "    return chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(query):\n",
    "        answer=respond(query)\n",
    "        return str(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    choice = input(\"Enter 'query' for rag query \\n 'entry' for rag entry\")\n",
    "    if choice == 'entry':\n",
    "        url = \"https://assets.techrepublic.com/uploads/2017/04/aexcelpowerbi.png\"\n",
    "        \n",
    "        data = generate_data(url)\n",
    "        final_data=prepare_embeddings(data,batch_size=10)\n",
    "    \n",
    "        initialize_qdrant(final_data[0][1])\n",
    "\n",
    "        qdrant_entry(final_data)\n",
    "    else:\n",
    "        demo = gr.Interface(\n",
    "        fn=processing,\n",
    "        inputs=[\"text\"],\n",
    "        outputs=[\"text\"],\n",
    "                )\n",
    "        demo.launch(debug=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

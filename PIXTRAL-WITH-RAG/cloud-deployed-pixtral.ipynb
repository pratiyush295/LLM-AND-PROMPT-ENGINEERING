{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install vllm\n",
    "!pip install --upgrade mistral_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm import LLM\n",
    "from vllm.sampling_params import SamplingParams\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import gradio as gr\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=LLM(\n",
    "    model=\"mistral-community/pixtral-12b-240910\",\n",
    "    tokenizer_mode=\"mistral\",\n",
    "    max_model_len=5000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class information(BaseModel):\n",
    "    heading:str\n",
    "    content:str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_context(image_url, prompt = \"Extract text from the image and give the response in JSON format\"):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    outputs = llm.chat(\n",
    "        messages,\n",
    "        sampling_params=SamplingParams(max_tokens=8192)\n",
    "    )\n",
    "\n",
    "    return outputs[0].outputs[0].text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_llm(context,query):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"You are an answer generation agent, you'll be given context and query, generate answer in human readable form\"},\n",
    "                {\"type\": \"text\", \"text\": f\"here is the question {query} and here is the context {context}\"}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    outputs = llm.chat(\n",
    "        messages,\n",
    "        sampling_params=SamplingParams(max_tokens=8192)\n",
    "    )\n",
    "\n",
    "    return outputs[0].outputs[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def process_query(url, query):\n",
    "    context = generate_context(url)\n",
    "    response = query_llm(context, query)\n",
    "    return response, context\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create the Gradio interface\n",
    "    interface = gr.Interface(\n",
    "        fn=process_query,\n",
    "        inputs=[\n",
    "            gr.Textbox(label=\"Enter the URL\", placeholder=\"Enter image URL here\"),\n",
    "            gr.Textbox(label=\"Enter your query\", placeholder=\"Ask a question about the content\")\n",
    "        ],\n",
    "        outputs=[\n",
    "            gr.Textbox(label=\"Response\"),\n",
    "            gr.Textbox(label=\"Json Parsed Data\"),\n",
    "        ],\n",
    "        title=\"Pixtral-12b RAG Application\",\n",
    "        description=\"Provide an image URL and ask questions based on the context generated from it.\"\n",
    "    )\n",
    "\n",
    "    # Launch the interface\n",
    "    interface.launch(share = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip -q install openai PyPDF2 sentence-transformers qdrant_client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import openai\n",
    "import PyPDF2\n",
    "import re\n",
    "from qdrant_client.models import PointStruct\n",
    "from qdrant_client.models import Distance, VectorParams\n",
    "from qdrant_client import QdrantClient\n",
    "import openai\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "qdrant_client = QdrantClient(\":memory:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pdf_reader = PyPDF2.PdfReader(\"soum_paul_profile_pdf.pdf\")\n",
    "pdf_corpus = []\n",
    "for page in pdf_reader.pages:\n",
    "    pdf_corpus.append(page.extract_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_paragraphs(pdf_corpus):\n",
    "    send = []\n",
    "    page_no = 1\n",
    "    for document in pdf_corpus:\n",
    "        section_no = 1\n",
    "        paragraphs = document.split(\".\\n\")\n",
    "        for para in paragraphs:\n",
    "            send.append([para,{'page_no': page_no, 'section_no': section_no}])\n",
    "            section_no += 1\n",
    "        page_no = page_no + 1\n",
    "    return send\n",
    "\n",
    "# data = [raw_text,{page_no, section_no}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_qdrant(length: int):\n",
    "    vector_size = length\n",
    "    # Define the vectors configuration\n",
    "    vector_params = VectorParams(\n",
    "        size=vector_size,                # Size of the vectors\n",
    "        distance=Distance.COSINE         # Choose distance metric (COSINE, EUCLID, or IP)\n",
    "    )\n",
    "    \n",
    "    # Create the collection with the specified configuration\n",
    "    if qdrant_client.get_collections().collections == []:\n",
    "        qdrant_client.create_collection(\n",
    "            collection_name=\"CHATBOT\",\n",
    "            vectors_config=vector_params  # Specify vector configuration\n",
    "        )\n",
    "    else:\n",
    "        if \"CHATBOT\" not in qdrant_client.get_collections().collections[0].name:\n",
    "            qdrant_client.create_collection(\n",
    "                collection_name=\"CHATBOT\",\n",
    "                vectors_config=vector_params  # Specify vector configuration\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(data_text):\n",
    "  return embeddings.encode(data_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_embeddings(data, batch_size=10):\n",
    "    total_items = len(data)\n",
    "    final_data = []\n",
    "    for item in data:  # Extract contexts for this batch\n",
    "        vectors = generate_embeddings(item[0])  # Generate embeddings for the batch\n",
    "        final_data.append([{\"raw_text\":item[0], \"page_no\": item[1]['page_no'], \"section_no\": item[1]['section_no']}, vectors])     \n",
    "        \n",
    "    return final_data\n",
    "# final_data = [{raw_text, page_no:, section_no}, vectors]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qdrant_entry(final_data):\n",
    "    points=[PointStruct( id=i,  vector=final_data[i][1],payload={'raw_context':final_data[i][0]['raw_text'], 'page_no':final_data[i][0]['page_no'], 'section_no':final_data[i][0]['section_no'] }) for i in range(len(final_data))]\n",
    "    qdrant_client.upsert(collection_name=\"CHATBOT\", points=points)\n",
    "    print(qdrant_client.get_collections())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_qdrant(query, collection_name='CHATBOT', limit=8):\n",
    "     \n",
    "    query_vector=generate_embeddings(query)\n",
    "     \n",
    "    result = qdrant_client.search(\n",
    "        collection_name = collection_name,\n",
    "        query_vector=query_vector,\n",
    "        limit = limit,\n",
    "        with_vectors = False\n",
    "    )\n",
    "    # search_result=[]\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_llm_context(result):\n",
    "    # result[0].payload['raw_context']\n",
    "    context =[]\n",
    "    for i in range(len(result)):\n",
    "        context.append(result[i].payload['raw_context'])\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_llm(context, query):\n",
    "    token = \"eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJGSjg2R2NGM2pUYk5MT2NvNE52WmtVQ0lVbWZZQ3FvcXRPUWVNZmJoTmxFIn0.eyJleHAiOjE3NTg1OTc3MzksImlhdCI6MTcyNzA2MTczOSwianRpIjoiMWFjMTQ0MzYtZDcyYS00ODQwLTkyMjEtNWJkYTA3MTA3ZTY0IiwiaXNzIjoiaHR0cDovL2dhdGV3YXkuZTJlbmV0d29ya3MuY29tL2F1dGgvcmVhbG1zL2FwaW1hbiIsImF1ZCI6ImFjY291bnQiLCJzdWIiOiI4NDQxNDc4Yy1hYjFlLTQzOWItYjQ1YS0xZWNkY2JhNmM3OWMiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJhcGltYW51aSIsInNlc3Npb25fc3RhdGUiOiI1N2I3M2VmMy03ZjFlLTQ1NTctYjM3Zi0yOTFjYWQ1YjNhZDkiLCJhY3IiOiIxIiwiYWxsb3dlZC1vcmlnaW5zIjpbIiJdLCJyZWFsbV9hY2Nlc3MiOnsicm9sZXMiOlsib2ZmbGluZV9hY2Nlc3MiLCJ1bWFfYXV0aG9yaXphdGlvbiIsImFwaXVzZXIiLCJkZWZhdWx0LXJvbGVzLWFwaW1hbiJdfSwicmVzb3VyY2VfYWNjZXNzIjp7ImFjY291bnQiOnsicm9sZXMiOlsibWFuYWdlLWFjY291bnQiLCJtYW5hZ2UtYWNjb3VudC1saW5rcyIsInZpZXctcHJvZmlsZSJdfX0sInNjb3BlIjoicHJvZmlsZSBlbWFpbCIsInNpZCI6IjU3YjczZWYzLTdmMWUtNDU1Ny1iMzdmLTI5MWNhZDViM2FkOSIsImVtYWlsX3ZlcmlmaWVkIjpmYWxzZSwibmFtZSI6IlByYXRpeXVzaCBLdW1hciIsInByaW1hcnlfZW1haWwiOiJzdXBlcnRlYW1zQGUyZW5ldHdvcmtzLmNvbSIsImlzX3ByaW1hcnlfY29udGFjdCI6ZmFsc2UsInByZWZlcnJlZF91c2VybmFtZSI6InByYXRpeXVzaC5rdW1hckBzdXBlcnRlYW1zLmFpIiwiZ2l2ZW5fbmFtZSI6IlByYXRpeXVzaCIsImZhbWlseV9uYW1lIjoiS3VtYXIiLCJlbWFpbCI6InByYXRpeXVzaC5rdW1hckBzdXBlcnRlYW1zLmFpIn0.FzwXSsbCEJ0xdqOO_jcv_NGf-TdifbdKT2JbavufhSlya5zHSEM7cy1VO4kIUzTsGizl-VT-0p-QHJnN05kfrYc9VezZb4R7paZBSjLwo9VDsYtOeBG3RWBqelm8zv9LsLtjuf55i1xJAsusqVigmTxfYnDxqnxKn6sbvk4LcJ0\"\n",
    "    openai.api_key = token\n",
    "    openai.base_url = \"https://infer.e2enetworks.net/project/p-1450/endpoint/is-2778/v1/\"\n",
    "​\n",
    "    completion = openai.chat.completions.create(\n",
    "        model=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an answer generation agent, you'll be given context and query, generate answer in human readable form\",\n",
    "                \n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"here's the question {query} and here's the context {'--'.join(context)}\"\n",
    "            },\n",
    "        ],\n",
    "​\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = tokenize_paragraphs(pdf_corpus)   #data = [raw_text,{page_no, section_no}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = prepare_embeddings(data)\n",
    "initialize_qdrant(len(final_data[0][1]))\n",
    "qdrant_entry(final_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Where is soum currently working at ? \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = query_qdrant(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_context = prepare_llm_context(result)\n",
    "response = query_llm(llm_context, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
